[
["index.html", "Exploratory Cognitive Diagnostic Models Welcome", " Exploratory Cognitive Diagnostic Models James Balamuta 2020-02-23 Welcome Welcome to the Exploratory Cognitive Diagnostic Models with R textbook. The textbook is part of a training initiative with respect to the ecdm package that implement the underlying methodology. "],
["intro.html", "Chapter 1 Introduction to Exploratory Cognitive Diagnostic Models 1.1 Installation 1.2 Loading the Package 1.3 Supplementary Data Sets 1.4 Help! 1.5 Notation", " Chapter 1 Introduction to Exploratory Cognitive Diagnostic Models Exploratory Cognitive Diagnostic Models (ECDMs) are versions of classicial Cognitive Diagnostic Models (CDMs) that do not require the component of an expertly crafted Q matrix. This class of models is new to the world of psychometric models. The goal of this textbook is to provide an overview of their implementation in the ecdm package from by the authors that developed it! Before we continue, please “bookmark” the ecdm repository on GitHub: https://github.com/tmsalab/ecdm The website provides direct access to the developers behind ecdm. In particular, it features the ability to file issues or bug reports, ask questions, or stay up-to-date in the latest breakthroughs. 1.1 Installation Before we can get started, please install the ecdm package from GitHub. The ecdm package is currently only available via GitHub as it is still being developed. As a result, installing by install.packages('ecdm') isn’t possible. As many of the routines are written in C++, the ecdm package requires a compiler to install. To assist in setting up the compiler, we’ve created the following guides: Windows: Rtools macOS: Rtools From there, please use the remotes package to retrieve the latest development version. if(!requireNamespace(&#39;remotes&#39;, quietly = TRUE)) install.packages(&quot;remotes&quot;) remotes::install_github(&quot;tmsalab/ecdm&quot;) 1.2 Loading the Package Accessing the ecdm rountines requires loading the package into R. Please load the ecdm package by pressing “run” library(ecdm) 1.3 Supplementary Data Sets The ecdm package has an accompanying data package called ecdmdata that comes equipped with three different data sets: Examination for the Certificate of Proficiency in English (ECPE), Templin, J. and Hoffman, L. (2013). items_ecpe, N = 2922 subject responses to J = 28 items. qmatrix_ecpe, J = 28 items and K = 3 traits. Fraction Addition and Subtraction, Tatsuoka, K. K. (1984). items_fractions: N = 536 subject responses to J = 20 items. qmatrix_fractions: J = 20 items and K = 8 traits. Revised PSVT:R, Culpepper and Balamuta (2013). items_spatial: N = 516 subject responses to J = 30 items. As time goes on, more data sets will likely be added. Let’s take a look at Fraction Addition and Subtraction data sets. Typing the name of each data set and running the command will load the data into R if the ecdmdata package is loaded. As these data sets are relatively big, let’s use the function head() to view on the first 6 rows. library(ecdmdata) head( items_fractions ) ## Item01 Item02 Item03 Item04 Item05 Item06 Item07 Item08 Item09 ## Subject001 0 0 0 1 0 0 1 1 0 ## Subject002 0 1 1 1 0 1 1 1 1 ## Subject003 0 1 1 1 0 1 1 1 0 ## Subject004 1 1 1 1 1 1 0 1 0 ## Subject005 0 0 0 1 0 1 0 1 0 ## Subject006 0 0 0 0 0 1 0 1 1 ## Item10 Item11 Item12 Item13 Item14 Item15 Item16 Item17 Item18 ## Subject001 1 1 1 0 1 1 1 0 1 ## Subject002 1 1 1 1 1 1 1 1 1 ## Subject003 0 0 0 0 1 1 1 0 0 ## Subject004 1 1 1 0 1 0 1 0 1 ## Subject005 0 0 1 0 0 0 0 0 0 ## Subject006 0 0 0 0 1 0 0 0 0 ## Item19 Item20 ## Subject001 1 1 ## Subject002 1 1 ## Subject003 0 0 ## Subject004 0 1 ## Subject005 0 0 ## Subject006 0 0 head( qmatrix_fractions ) ## Trait1 Trait2 Trait3 Trait4 Trait5 Trait6 Trait7 Trait8 ## Item01 0 0 0 1 0 1 1 0 ## Item02 0 0 0 1 0 0 1 0 ## Item03 0 0 0 1 0 0 1 0 ## Item04 0 1 1 0 1 0 1 0 ## Item05 0 1 0 1 0 0 1 1 ## Item06 0 0 0 0 0 0 1 0 Within this textbook, the following notation will be used for dimensions: \\(K\\): Number of Traits (columns) in the Q Matrix \\(J\\): Number of Items (rows/columns) in the Q Matrix and Item Matrix \\(N\\): Number of Subjects (rows) in the Item Matrix To retrieve this information in R, we can use the dimension function, dim(), which lists the size of the data as rows by columns. Find the dimensions of the items_fractions and qmatrix_fractions dim(items_fractions) ## [1] 536 20 dim(qmatrix_fractions) ## [1] 20 8 1.4 Help! Each function within the package contains a help file that provides documentation on the implementation. Moreover, some of the functions have worked examples as well. To view this information type either ?function_name or help(function_name). Let’s verify the previously acquired numbers for the items_fractions data set by checking the entry in the documentation. ?items_fractions If you are curious to see how a function performs, you can opt to use example(function_name, package = &quot;ecdm&quot;). Be aware that some examples may take considerably longer than the rest to run. 1.5 Notation For consistency, we aim to use the following notation. Denoting individuals: \\(N\\) is the total number of individuals taking the assessment. \\(i\\) is the current individual. Denoting items: \\(J\\) is the total number of items on the assessment. \\(j\\) is the current item \\(Y_{ij}\\) is the observed binary response for individual \\(i\\) (\\(1\\leq i \\leq N\\)) to item \\(j\\) (\\(1\\leq j\\leq J\\)). \\(s_j\\) is the probability of slipping on item \\(j\\). \\(g_j\\) is the probability of guessing on item \\(j\\). Denoting attributes: \\(K\\) is the total number of attributes for the assessment item. \\(k\\) is the current attribute. \\(\\boldsymbol\\alpha_i=\\left(\\alpha_{i1},\\dots,\\alpha_{iK}\\right)^\\prime\\) where \\(\\boldsymbol\\alpha_i\\in \\left\\{0,1\\right\\}^K\\) and \\(\\alpha_{ik}\\) is the latent binary attribute for individual \\(i\\) on attribute \\(k\\) (\\(1\\leq k\\leq K\\)). Denoting the skill/attribute “Q” matrix: \\(\\boldsymbol q_{j}=\\left(q_{j1},\\dots,q_{jK}\\right)^\\prime\\) be the \\(j\\)th row of \\(\\boldsymbol Q\\) such that \\(q_{jk}=1\\) if attribute \\(k\\) is required for item \\(j\\) and zero otherwise. "],
["simcdm.html", "Chapter 2 simcdm: Simulate Cognitive Diagnostic Model Data 2.1 Matrix Simulation 2.2 DINA Simulation 2.3 rRUM Simulation", " Chapter 2 simcdm: Simulate Cognitive Diagnostic Model Data 2.1 Matrix Simulation Simulations within this section are done underneath the following settings. # Set a seed for reproducibility set.seed(888) # Setup Parameters N = 15 # Number of Examinees / Subjects J = 10 # Number of Items K = 2 # Number of Skills / Attributes 2.1.1 Attribute profile simulation Generate latent attribute profile classes (\\(2^K\\) latent classes by \\(K\\) skills). # Create a listing of all attribute classes class_alphas = attribute_classes(K) class_alphas ## [,1] [,2] ## [1,] 0 0 ## [2,] 0 1 ## [3,] 1 0 ## [4,] 1 1 Generate latent attribute profile class for each subject (\\(N\\) subjects by \\(K\\) skills). # Set a seed for reproducibility set.seed(5126) # Create attributes for a subject subject_alphas = sim_subject_attributes(N, K) subject_alphas ## [,1] [,2] ## [1,] 0 0 ## [2,] 1 1 ## [3,] 1 0 ## [4,] 1 1 ## [5,] 0 0 ## [6,] 0 1 ## [7,] 0 1 ## [8,] 1 0 ## [9,] 0 1 ## [10,] 0 1 ## [11,] 0 1 ## [12,] 0 1 ## [13,] 1 0 ## [14,] 0 0 ## [15,] 1 0 # Equivalent to: # subject_alphas = class_alphas[sample(2 ^ K, N, replace = TRUE),] 2.1.2 Identifiable Q Matrix Simulation Simulate an identifiable \\(Q\\) matrix (\\(J\\) items by \\(K\\) skills). # Set a seed for reproducibility set.seed(1512) # Simulate an identifiable Q matrix Q = sim_q_matrix(J, K) Q ## [,1] [,2] ## [1,] 1 0 ## [2,] 1 0 ## [3,] 0 1 ## [4,] 0 1 ## [5,] 0 1 ## [6,] 0 1 ## [7,] 1 1 ## [8,] 1 0 ## [9,] 1 0 ## [10,] 0 1 2.2 DINA Simulation Simulations within this section are done underneath the following settings. # Set a seed for reproducibility set.seed(888) # Setup Parameters N = 15 # Number of Examinees / Subjects J = 10 # Number of Items K = 2 # Number of Skills / Attributes # Assign slipping and guessing values for each item ss = gs = rep(.2, J) # Simulate identifiable Q matrix Q = sim_q_matrix(J, K) # Simulate subject attributes subject_alphas = sim_subject_attributes(N, K) 2.2.1 DINA Item Simulation Simulate item data, \\(Y\\), under DINA model (\\(N\\) by \\(J\\)) # Set a seed for reproducibility set.seed(2019) # Simulate items under the DINA model items_dina = sim_dina_items(subject_alphas, Q, ss, gs) items_dina ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 0 0 0 1 1 0 0 0 1 1 ## [2,] 1 1 1 0 1 1 1 1 0 1 ## [3,] 0 0 0 0 1 0 0 0 1 1 ## [4,] 1 1 1 0 0 0 1 1 1 0 ## [5,] 1 1 1 1 1 1 1 1 1 1 ## [6,] 1 1 1 1 0 1 0 1 0 1 ## [7,] 0 0 0 1 1 0 0 0 0 1 ## [8,] 1 0 1 1 1 0 0 1 0 1 ## [9,] 1 1 1 1 0 1 1 1 1 1 ## [10,] 0 1 0 1 1 0 0 0 1 1 ## [11,] 1 1 1 1 1 1 1 0 1 1 ## [12,] 0 0 0 0 1 0 0 0 1 0 ## [13,] 0 0 0 0 1 0 0 0 1 1 ## [14,] 1 0 0 1 1 0 0 0 0 0 ## [15,] 1 1 0 1 0 0 1 1 0 0 2.2.2 DINA Attribute Simulation Simulate attribute data under DINA model (\\(N\\) by \\(J\\)) # Set a seed for reproducibility set.seed(51823) # Simulate attributes under the DINA model attributes = sim_dina_attributes(subject_alphas, Q) attributes ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 0 0 0 1 1 0 0 0 1 1 ## [2,] 1 1 1 1 1 1 1 1 1 1 ## [3,] 0 0 0 1 1 0 0 0 1 1 ## [4,] 1 1 1 0 0 0 1 1 0 0 ## [5,] 1 1 1 1 1 1 1 1 1 1 ## [6,] 1 1 1 1 1 1 1 1 1 1 ## [7,] 0 0 0 1 1 0 0 0 1 1 ## [8,] 1 1 1 1 1 1 1 1 1 1 ## [9,] 1 1 1 1 1 1 1 1 1 1 ## [10,] 0 0 0 1 1 0 0 0 1 1 ## [11,] 1 1 1 1 1 1 1 1 1 1 ## [12,] 0 0 0 1 1 0 0 0 1 1 ## [13,] 0 0 0 1 1 0 0 0 1 1 ## [14,] 0 0 0 0 0 0 0 0 0 0 ## [15,] 1 1 1 0 0 0 1 1 0 0 2.3 rRUM Simulation The rRUM simulations are done using the following settings. # Set a seed for reproducibility set.seed(888) # Setup Parameters N = 15 # Number of Examinees / Subjects J = 10 # Number of Items K = 2 # Number of Skills / Attributes # The probabilities of answering each item correctly for individuals # who do not lack any required attribute pistar = rep(.9, J) # Simulate an identifiable Q matrix Q = sim_q_matrix(J, K) # Penalties for failing to have each of the required attributes rstar = .5 * Q # Latent Class Probabilities pis = c(.1, .2, .3, .4) # Generate latent attribute profile with custom probability (N subjects by K skills) subject_alphas = sim_subject_attributes(N, K, prob = pis) # Equivalent to: # class_alphas = attribute_classes(K) # subject_alphas = class_alphas[sample(2 ^ K, N, replace = TRUE, prob = pis),] 2.3.1 Simulate rRUM items Simulate rRUM item data \\(Y\\) (\\(N\\) by \\(J\\)) # Set a seed for reproducibility set.seed(912) # Generate rRUM items rrum_items = sim_rrum_items(Q, rstar, pistar, subject_alphas) rrum_items ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 1 1 0 1 0 1 1 1 0 ## [2,] 1 1 0 1 1 0 1 0 0 0 ## [3,] 0 1 1 1 0 1 1 1 0 0 ## [4,] 0 1 1 1 0 1 1 1 1 0 ## [5,] 1 1 0 0 1 0 1 1 1 0 ## [6,] 1 1 1 1 0 0 1 1 0 1 ## [7,] 1 0 1 0 1 0 0 0 0 1 ## [8,] 0 0 1 0 0 0 1 0 0 1 ## [9,] 0 1 0 1 1 1 0 1 1 0 ## [10,] 1 1 1 1 0 0 0 1 1 0 ## [11,] 1 1 1 0 0 0 1 1 0 1 ## [12,] 0 1 0 1 1 0 1 1 1 1 ## [13,] 1 0 1 1 1 0 1 1 1 1 ## [14,] 1 0 1 1 1 1 1 1 1 1 ## [15,] 0 0 1 0 1 1 1 1 1 1 "],
["edina.html", "Chapter 3 EDINA: Exploratory Deterministic Input, Noisy “And” Gate 3.1 Methodology 3.2 Single Model Estimation 3.3 Comparing Multiple Models", " Chapter 3 EDINA: Exploratory Deterministic Input, Noisy “And” Gate 3.1 Methodology 3.2 Single Model Estimation When working with a single \\(K\\) dimension, the easiest way to proceed is to use the edina function. This function requires: data: Item Matrix k: Number of Traits associated with the Q Matrix. burnin: Amount of iterations to discard chain_length: Amount of iterations to keep model = edina(Y, k = 3, burnin = 10000, chain_length = 20000) Let’s take the fraction-subtraction data that we loaded earlier and perform an estimation with it using k = 2. Please note it will take about 3 minutes to complete. edina_fractions_k2 = edina(data = items_fractions, k = 2) 3.2.1 Structure of EDINA Underneath the edina_fractions_k2 variable is a wealth of information regarding the model fit. This information can be used in subseqent analysis. To aide in this endeavor, we’ve crafted a series of helper functions that will be discussed next. In the interim, please feel free to look at the underlying structure of edina_fractions_k2 using str(). str(edina_fractions_k2) ## List of 15 ## $ coefficients : num [1:20, 1:4] 0.0712 0.0757 0.027 0.2211 0.3048 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:20] &quot;Item1&quot; &quot;Item2&quot; &quot;Item3&quot; &quot;Item4&quot; ... ## .. ..$ : chr [1:4] &quot;Guessing&quot; &quot;SD(Guessing)&quot; &quot;Slipping&quot; &quot;SD(Slipping)&quot; ## $ loglike_summed: num -93840906 ## $ loglike_pmean : num -4671 ## $ pi_classes : num [1:4, 1] 0.3858 0.141 0.0301 0.4431 ## $ avg_q : num [1:20, 1:2] 0 0 0 1 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:20] &quot;Item1&quot; &quot;Item2&quot; &quot;Item3&quot; &quot;Item4&quot; ... ## .. ..$ : chr [1:2] &quot;Trait1&quot; &quot;Trait2&quot; ## $ est_q : num [1:20, 1:2] 0 0 0 1 0 0 0 1 1 1 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:20] &quot;Item1&quot; &quot;Item2&quot; &quot;Item3&quot; &quot;Item4&quot; ... ## .. ..$ : chr [1:2] &quot;Trait1&quot; &quot;Trait2&quot; ## $ or_tested : num [1:20, 1:20] 0 0 0 0 0 0 0 0 0 0 ... ## $ sample_or : num [1:20, 1:20] 0 0 0 0 0 0 0 0 0 0 ... ## $ n : int 536 ## $ j : int 20 ## $ k : int 2 ## $ burnin : num 10000 ## $ chain_length : num 20000 ## $ timing : Named num [1:3] 62.282 0.015 62.3 ## ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;user.self&quot; &quot;sys.self&quot; &quot;elapsed&quot; ## $ dataset_name : chr &quot;items_fractions&quot; ## - attr(*, &quot;class&quot;)= chr &quot;edina&quot; The details on the return values contained in the EDINA model can be found in ?edina. 3.2.2 Extracting the Q Matrix As the Q matrix is estimated, there are two ways to extract the Q matrix. The first way involves looking directly at the average and the second way involves looking at the dichotomous state of the Q matrix (default). The latter is constructed by treating element-wise entries with values greater than 0.5 as being 1 and values less than 0.5 as being 0. Extracting the Q matrix from an estimated model can be done using extract_q_matrix(x, binary_q = TRUE) Let’s view both forms of the estimated Q Matrix for edina_fractions_k2 extract_q_matrix(edina_fractions_k2) ## Trait1 Trait2 ## Item1 0.00000 1.00000 ## Item2 0.00000 1.00000 ## Item3 0.00000 1.00000 ## Item4 1.00000 0.13255 ## Item5 0.00000 1.00000 ## Item6 0.00000 1.00000 ## Item7 0.00000 1.00000 ## Item8 0.97990 0.99595 ## Item9 0.99420 0.99985 ## Item10 1.00000 0.02235 ## Item11 1.00000 0.00000 ## Item12 0.29850 0.70215 ## Item13 1.00000 1.00000 ## Item14 0.00000 1.00000 ## Item15 0.00000 1.00000 ## Item16 0.06445 0.93745 ## Item17 1.00000 0.00000 ## Item18 1.00000 0.00005 ## Item19 1.00000 0.99995 ## Item20 1.00000 0.00000 extract_q_matrix(edina_fractions_k2, binary_q = TRUE) ## Trait1 Trait2 ## Item1 0 1 ## Item2 0 1 ## Item3 0 1 ## Item4 1 0 ## Item5 0 1 ## Item6 0 1 ## Item7 0 1 ## Item8 1 1 ## Item9 1 1 ## Item10 1 0 ## Item11 1 0 ## Item12 0 1 ## Item13 1 1 ## Item14 0 1 ## Item15 0 1 ## Item16 0 1 ## Item17 1 0 ## Item18 1 0 ## Item19 1 1 ## Item20 1 0 An alternative way to view the estimated Q matrix is to plot it on a graph. Graphing a Q matrix is done using a heatmap to show areas strength of the estimation for a given item and trait. The underlying graphs for ecdm are constructed using the ggplot2 library and, thus, can be further manipulated by adding new layers to the plot. q_graph(x, binary_q = TRUE, ...) How does the average Q matrix plot differ from the dichotomous Q matrix plot? q_graph(edina_fractions_k2) q_graph(edina_fractions_k2, binary_q = FALSE) 3.2.3 Extracting the Model Coefficients Outside of the estimated Q matrix, you also have the estimated slipping and guessing parameters for the EDINA model. Recall: Guessing represents guessing or the probability of correctly answering item \\(j\\) when at least one attribute is lacking, e.g. \\(g_j=P\\left(Y_{ij}=1|\\eta_{ij}=0\\right)\\) Slipping represents slipping or the probability of an incorrect response for individuals with all of the required attributes, e.g. \\(s_j=P\\left(Y_{ij}=0|\\eta_{ij}=1\\right)\\). These coefficients can be retrieved using either coef() or coefficients() akin to base R. coef(edina_fractions_k2) # or: coefficients(edina_fractions_k2) ## Guessing SD(Guessing) Slipping SD(Slipping) ## Item1 0.07122652 0.018789967 0.14108199 0.020152254 ## Item2 0.07569449 0.020013270 0.06824275 0.015039251 ## Item3 0.02698653 0.014703219 0.13807849 0.019806591 ## Item4 0.22112037 0.026061723 0.12578350 0.021945289 ## Item5 0.30476626 0.031127407 0.21850436 0.023712028 ## Item6 0.53652583 0.033753208 0.02510464 0.008884901 ## Item7 0.02517658 0.011554679 0.33296921 0.027177836 ## Item8 0.58404755 0.029383234 0.05382223 0.015911676 ## Item9 0.51316566 0.029305936 0.18846420 0.025805495 ## Item10 0.03385231 0.011589874 0.22674090 0.027093081 ## Item11 0.06855694 0.015388724 0.07440054 0.017605533 ## Item12 0.48304034 0.044582849 0.07406747 0.020937753 ## Item13 0.01748661 0.008138668 0.35542825 0.030842162 ## Item14 0.41547980 0.033385357 0.06322286 0.014426010 ## Item15 0.05460958 0.016031512 0.26546315 0.025597122 ## Item16 0.41039489 0.037750229 0.09799984 0.019094943 ## Item17 0.05058086 0.014311418 0.14062367 0.022298586 ## Item18 0.13095644 0.020758565 0.15592299 0.023078870 ## Item19 0.02451213 0.009345748 0.33160007 0.030629486 ## Item20 0.01533473 0.008277803 0.18736865 0.024921173 3.2.4 Check Identifiability Any Q matrix can be checked to ensure that the identifiability conditions are met. In particular, we have: For a \\(J\\times J\\) permutation matrix \\(\\mathbf P\\), \\(\\mathbf Q\\) can be expressed as, \\[ \\mathbf P\\mathbf Q = \\left[\\begin{array}{c} \\mathbf I_K \\\\ \\mathbf I_K\\\\ \\widetilde{\\mathbf Q} \\end{array}\\right],\\] where \\(\\mathbf I_K\\) is a \\(K\\times K\\) identity matrix and \\(\\widetilde{\\mathbf Q}\\) is a \\(\\left(J-2K\\right)\\times K\\) sub-matrix of \\(\\mathbf Q\\) with column \\(k\\) denoted by \\(\\widetilde{\\mathbf Q}_k\\). Each skill loads onto at least three items, which implies \\(\\mathbf Q_k^\\prime \\mathbf 1_J \\geq 3\\) where \\(\\mathbf 1_J\\) is a \\(J\\) dimensional vector of ones. Similarly, if \\(c_k\\) is the \\(k\\)th column margin for \\(\\widetilde{\\mathbf Q}\\) (i.e., \\(c_k = \\widetilde{\\mathbf Q}_k^\\prime \\mathbf 1_{J-2K}\\)) this condition is equivalent to \\(c_k&gt;0\\). Each item loads onto at least one skill such that \\(\\mathbf q_j^\\prime \\mathbf1_K&gt;0\\). To verify a Q matrix is identifiable, we can use check_identifiability(). example_Q = extract_q_matrix(edina_fractions_k2) # Todo: switch to is_identifiable # check_identifiability(example_Q) 3.3 Comparing Multiple Models With the ability to estimate a variety of model under the exploratory framework, there is interest in being able to select which model and, subsequently, Q matrix is preferred. To aide in this endeavor, there exists: auto_edina(data, k = 2:4, burnin = 10000, chain_length = 20000, save_results = FALSE, save_filename = &quot;edina_model_data&quot;) This function is slightly different than edina in the sense that it takes a range of dimensions in the k parameter. Furthermore, it offers the ability to save model objects independently of one another. This is useful for estimating higher dimensions. Let’s estimate the models for items_fractions that have been 2 and 4 traits. many_edina_fractions = auto_edina( items_fractions , k = 2:4) ## Starting the estimation procedure ... ## Working on k = 2 ... ## Time Elapsed: 63.648 ## Working on k = 3 ... ## Time Elapsed: 109.915 ## Working on k = 4 ... ## Time Elapsed: 198.309 many_edina_fractions ## The results of searching Q-matrices between 2 and 4 ... ## k bic dic heuristic ## 2 10119 9672 0.4895 ## 3 9726 9135 0.4526 ## 4 9705 8939 0.4526 3.3.1 Best Model As the auto_edina() model contains a set of models, we need an efficient way of deciding which model to use. For performing model selection, the package implements three different information criterion: deviance information criterion (DIC), bayesian information criterion (BIC), and computing posterior predictive probabilities (PPPs) of the item means and odds ratios for each pair of items. PPPs smaller than 0.05 or greater than 0.95 to be extreme and evidence of misfit. \\[DIC = -2\\left({\\log p\\left( {\\mathbf{y}| \\mathbf{\\hat{\\theta}} } \\right) - 2\\left( {\\log p\\left( {\\mathbf{y}| \\mathbf{\\hat{\\theta}} } \\right) - \\frac{1}{N}\\sum\\limits_{n = 1}^N {\\log p\\left( {\\mathbf{y}|{\\mathbf{\\theta} _s}} \\right)} } \\right)} \\right)\\] \\[BIC = -2 \\log p\\left( {\\mathbf{y}| \\mathbf{\\hat{\\theta}} } \\right) + (k+j)\\log(n) \\] \\(PPP\\) Procedure: simulating observed responses \\(\\mathbf Y^{(r)}\\) using model parameters from iteration \\(r\\) of the MCMC sampler computing the odds ratio for each pair of items at iteration \\(r\\) as \\(OR^{(r)} = n_{11}^{(r)}n_{00}^{(r)}/\\left(n_{10}^{(r)}n_{01}^{(r)}\\right)\\) here \\(n_{11}^{(r)}\\) is the frequency of ones on both variables at iteration \\(r\\), \\(n_{10}^{(r)}\\) is the frequency of ones on the first item and zeros on the second at iteration \\(r\\), etc.; and computing PPPs for each item pair as the proportion of generated \\(OR^{(r)}\\)’s that exceeded elements of the observed odds ratios. We can individually apply these methods to an edina object. By default, auto_edina() computes and saves the result. DIC(edina_fractions_k2) ## [1] 9426.435 BIC(edina_fractions_k2) ## [1] 9869.614 model_heuristic(edina_fractions_k2, alpha = 0.05) ## PPP ## [1] 0.4052632 When viewing the variable containing the results of auto_edina(), the model selection information will be displayed. many_edina_fractions ## The results of searching Q-matrices between 2 and 4 ... ## k bic dic heuristic ## 2 10119 9672 0.4895 ## 3 9726 9135 0.4526 ## 4 9705 8939 0.4526 To extract the “best model”, we can use the best_model() function with an appropriate ic selection of either: “heuristic” (PPP), “bic”, or “dic”. best_edina_fractions = best_model(many_edina_fractions) best_edina_fractions ## The EDINA model for data with K = 3 ## ## The model fit is as follows: ## k bic dic heuristic ## 3 9726.208 9134.803 0.4526316 ## ## The estimated coefficients for the EDINA model are: ## Guessing SD(Guessing) Slipping SD(Slipping) ## Item1 0.042310 0.016233 0.13641 0.01968 ## Item2 0.052490 0.017322 0.06862 0.01490 ## Item3 0.009615 0.009018 0.14216 0.02022 ## Item4 0.205512 0.027935 0.12391 0.02110 ## Item5 0.309724 0.031307 0.21319 0.02440 ## Item6 0.311496 0.047629 0.04187 0.01076 ## Item7 0.034765 0.015716 0.33795 0.02857 ## Item8 0.580603 0.030456 0.05366 0.01584 ## Item9 0.346158 0.044797 0.24968 0.02234 ## Item10 0.027836 0.010947 0.22889 0.02704 ## Item11 0.069236 0.015571 0.07181 0.01729 ## Item12 0.204721 0.040968 0.09183 0.01571 ## Item13 0.018518 0.008336 0.35122 0.03137 ## Item14 0.099343 0.038027 0.06550 0.01412 ## Item15 0.059198 0.016587 0.25131 0.02553 ## Item16 0.124585 0.035715 0.10890 0.01719 ## Item17 0.049741 0.013981 0.13736 0.02206 ## Item18 0.131878 0.020573 0.15445 0.02293 ## Item19 0.025475 0.009584 0.32668 0.03077 ## Item20 0.015159 0.008012 0.18518 0.02478 ## ## The estimated Q matrix is: ## Trait1 Trait2 Trait3 ## Item1 0.0000 1.00000 0.0000 ## Item2 0.0000 1.00000 0.0000 ## Item3 0.0000 1.00000 0.0000 ## Item4 0.1755 0.01135 1.0000 ## Item5 0.7986 1.00000 0.0000 ## Item6 1.0000 0.00000 0.0000 ## Item7 0.4016 1.00000 0.0000 ## Item8 0.1925 0.92820 0.9866 ## Item9 0.9997 0.00350 0.0034 ## Item10 0.2403 0.00145 1.0000 ## Item11 0.9352 0.00000 1.0000 ## Item12 1.0000 0.00000 0.0000 ## Item13 0.8915 1.00000 1.0000 ## Item14 1.0000 0.00000 0.0000 ## Item15 1.0000 1.00000 0.0000 ## Item16 1.0000 0.00000 0.0000 ## Item17 0.8017 0.00000 1.0000 ## Item18 0.8312 0.00000 1.0000 ## Item19 0.8972 0.99995 1.0000 ## Item20 0.8076 0.00000 1.0000 The output reverts to what is shown during a traditional edina estimation. This will similarly be the case if you use extract_q_matrix() on an auto_edina() object. 3.3.2 Visually Comparing Models To better understand the set of models that was estimated, we can take a look at the collection of their values. There two graphs of particular interest here: model selection criterion changes over time. parameter evolution over time of slipping and guessing parameter_evolution_graph(many_edina_fractions) model_selection_graph(many_edina_fractions) "],
["references.html", "References", " References "]
]
